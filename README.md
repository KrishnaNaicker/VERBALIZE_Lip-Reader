# VERBALIZE Lip-Reader

A deep learning model based on TensorFlow used for lip reading.

## Overview

This project focuses on creating a deep learning model that can interpret and understand lip movements to predict spoken words. The model is implemented using TensorFlow and is designed to enhance speech recognition systems by incorporating visual cues from lip movements.

## Features

- **Deep Learning Model**: Utilizes TensorFlow for building and training the lip-reading model.
- **Jupyter Notebook**: Contains the raw implementation in a Jupyter Notebook.
- **High Accuracy**: Aims to improve the accuracy of speech recognition by combining visual and audio data.

## Installation

1. Clone the repository:
    ```bash
    git clone https://github.com/RuchirKalokhe/VERBALIZE_Lip-Reader.git
    cd VERBALIZE_Lip-Reader
    ```
2. Install the required dependencies:
    ```bash
    pip install -r requirements.txt
    ```

## Usage

1. Navigate to the project directory.
2. Open the Jupyter Notebook `VERBALIZE_backend.ipynb`.
3. Follow the instructions in the notebook to preprocess the data, train the model, and test its performance.

## Project Structure

- `app/`: Directory containing application-specific files.
- `.gitattributes`: Git attributes file.
- `requirements.txt`: File listing all dependencies.
- `VERBALIZE_backend.ipynb`: Jupyter Notebook for the raw implementation. (Feel free to play around with larger data sets:)

## Contributing

Contributions are welcome! Please fork the repository and submit a pull request for any improvements or bug fixes.

## License

This project is licensed under the MIT License. See the LICENSE file for more details.

## Contact

For any questions or inquiries, please contact [Ruchir Kalokhe](https://github.com/RuchirKalokhe).
